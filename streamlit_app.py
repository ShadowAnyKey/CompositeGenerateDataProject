import streamlit as st
import requests
import matplotlib.pyplot as plt
import pandas as pd
import io
import seaborn as sns
import configparser
import os

st.title("üìä –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∞–Ω–∞–ª–∏–∑–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")

API_URL = "http://127.0.0.1:8000"

mode = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞:", [
    "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
    "–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑",
    "–ê–Ω–∞–ª–∏–∑ Excel-–æ–±—Ä–∞–∑—Ü–æ–≤"
])

if mode == "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑":
    st.header("üîç –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (—Ä–µ–∞–ª—å–Ω—ã–µ vs –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ)")

    real_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã", type="xlsx", accept_multiple_files=True)
    virt_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã", type="xlsx", accept_multiple_files=True)

    error_threshold = st.slider("–ü–æ—Ä–æ–≥ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏ (%)", 5, 30, 15)
    pair_only = st.checkbox("–°—Ç—Ä–æ–≥–æ–µ –ø–∞—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ", False)

    if real_files and virt_files and st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"):
        files = []
        for f in real_files:
            files.append(('real_files', (f.name, f.getvalue(), 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')))
        for f in virt_files:
            files.append(('virt_files', (f.name, f.getvalue(), 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')))

        data = {
            'error_threshold': error_threshold,
            'pair_only': 'true' if pair_only else 'false'
        }

        response = requests.post(f"{API_URL}/classic-analysis/", files=files, data=data)

        if response.ok:
            res_json = response.json()

            st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {res_json['matched_count']}")

            # –ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ
            st.subheader("üìà –ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞:")
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç—Ä–∏–∫ –≤ DataFrame: —Å—Ç—Ä–æ–∫–∏ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Å—Ç–æ–ª–±—Ü—ã ‚Äî –º–µ—Ç—Ä–∏–∫–∏
            metrics_df = pd.DataFrame(res_json['results_metrics']).T
            # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–º –∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            metrics_df = metrics_df[['RMSE', 'MAE', 'R2']]
            metrics_df.index.name = '–ü–∞—Ä–∞–º–µ—Ç—Ä'
            st.dataframe(metrics_df)

            # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
            st.subheader("üßê –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö:")
            eval_df = pd.DataFrame(list(res_json['metrics_evaluation'].items()), columns=['–ü–∞—Ä–∞–º–µ—Ç—Ä', '–û—Ü–µ–Ω–∫–∞'])
            st.dataframe(eval_df)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
            st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã:")
            tests_data = []
            for param, values in res_json['statistical_tests'].items():
                tests_data.append({
                    '–ü–∞—Ä–∞–º–µ—Ç—Ä': param,
                    't-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞': values['t_stat'],
                    'p-–∑–Ω–∞—á–µ–Ω–∏–µ': values['p_value'],
                    '–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ?': "‚úÖ –î–∞" if values['significant'] else "‚ùå –ù–µ—Ç"
                })
            tests_df = pd.DataFrame(tests_data)
            st.dataframe(tests_df)

            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
            st.subheader("üîó –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã:")
            matched_df = pd.DataFrame(res_json['matched_experiments'])
            st.dataframe(matched_df)

            # 1) Scatter ¬´—Ä–µ–∞–ª vs –≤–∏—Ä—Ç—É–∞–ª¬ª –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
            st.subheader("üìà –î–∏–∞–≥—Ä–∞–º–º—ã —Ä–∞—Å—Å–µ—è–Ω–∏—è (–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ vs —Ä–µ–∞–ª—å–Ω—ã–µ)")
            for m, pairs in res_json['metrics_raw'].items():
                fig, ax = plt.subplots(figsize=(5,4))
                real_vals, virt_vals = zip(*pairs)
                ax.scatter(real_vals, virt_vals, alpha=0.7)
                ax.plot([min(real_vals+virt_vals), max(real_vals+virt_vals)]*2,
                        [min(real_vals+virt_vals), max(real_vals+virt_vals)]*2,
                        linestyle='--')
                ax.set_xlabel("–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                ax.set_ylabel("–í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                ax.set_title(f"–î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å—Å–µ—è–Ω–∏—è: {m}")
                ax.grid(True)
                st.pyplot(fig)

            # 2) Boxplot —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ (Real ‚Äì Virt)
            st.subheader("üì¶ –Ø—â–∏–∫ —Å —É—Å–∞–º–∏ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–µ–π")
            for m, pairs in res_json['metrics_raw'].items():
                errors = [r - v for r, v in pairs]
                fig, ax = plt.subplots(figsize=(4,3))
                sns.boxplot(x=errors, ax=ax)
                ax.set_title(f"–Ø—â–∏–∫ —Å —É—Å–∞–º–∏ –æ—à–∏–±–æ–∫: {m}")
                ax.set_xlabel("–û—à–∏–±–∫–∞ (Real ‚àí Virt)")
                ax.grid(True)
                st.pyplot(fig)

        else:
            st.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä.")

elif mode == "–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑":
    # –ß—Ç–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = configparser.ConfigParser()
    config_path = os.path.join(os.path.dirname(__file__), 'config.cfg')
    if not os.path.exists(config_path):
        st.error(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
        st.stop()
    config.read(config_path)
    if 'neural_analysis_ui' not in config:
        st.error("–í —Ñ–∞–π–ª–µ config.cfg –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–µ–∫—Ü–∏—è [neural_analysis_ui]")
        st.stop()
    ui_cfg = config['neural_analysis_ui']

    # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ cfg
    default_polymer = ui_cfg.getfloat('polymer_solution_pct', 20.0)
    default_length = ui_cfg.getfloat('length_mm', 236.0)
    default_mass = ui_cfg.getfloat('mass_mg', 261.0)
    default_fiber = ui_cfg.getfloat('fiber_content_pct', 72.34)

    st.header("üß† –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")

    csv_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è", type="csv", accept_multiple_files=True)
    polymer_solution_pct = default_polymer  # –†–∞—Å—Ç–≤–æ—Ä –ø–æ–ª–∏–º–µ—Ä–∞ (%)
    length_mm = default_length            # –î–ª–∏–Ω–∞ –æ–±—Ä–∞–∑—Ü–∞ (–º–º)
    mass_mg = default_mass               # –ú–∞—Å—Å–∞ –æ–±—Ä–∞–∑—Ü–∞ (–º–≥)
    fiber_content_pct = default_fiber     # –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–æ–ª–æ–∫–Ω–∞ (%)
    num_samples = st.number_input("–°–∫–æ–ª—å–∫–æ –æ–±—Ä–∞–∑—Ü–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å?", min_value=1, max_value=20, value=3, step=1)

    if csv_files and st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑"):
        files = [('csv_files', (f.name, f.getvalue())) for f in csv_files]

        response = requests.post(
            f"{API_URL}/neural-analysis/",
            files=files,
            data={
                'polymer_solution_pct': polymer_solution_pct,
                'length_mm': length_mm,
                'mass_mg': mass_mg,
                'fiber_content_pct': fiber_content_pct,
                'num_samples': num_samples
            }
        )

        if response.ok:
            excel_buffer = io.BytesIO(response.content)

            st.download_button(
                label="–°–∫–∞—á–∞—Ç—å Excel —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏",
                data=excel_buffer,
                file_name="multiple_predicted_samples.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            st.success("–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –≥–æ—Ç–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        else:
            st.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä.")

elif mode == "–ê–Ω–∞–ª–∏–∑ Excel-–æ–±—Ä–∞–∑—Ü–æ–≤":
    st.header("üìà –ê–Ω–∞–ª–∏–∑ Excel-—Ñ–∞–π–ª–æ–≤ (–ø–æ –ª–∏—Å—Ç–∞–º)")

    excel_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª—ã —Å –æ–±—Ä–∞–∑—Ü–∞–º–∏", type="xlsx", accept_multiple_files=True)
    skip_initial_rows = st.number_input("–°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–≤–µ—Ä—Ö—É —Ñ–∞–π–ª–∞?", min_value=0, value=3, step=1)

    show_only_good = st.checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–∏–µ –æ–±—Ä–∞–∑—Ü—ã", False)

    if excel_files and st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ Excel-—Ñ–∞–π–ª–æ–≤"):
        files = [('excel_files', (f.name, f.getvalue())) for f in excel_files]

        data = {'skip_initial_rows': skip_initial_rows}

        response = requests.post(
            f"{API_URL}/excel-sample-analysis/",
            files=files,
            data=data
        )

        if response.ok:
            results = response.json()
            for file_name, sheets in results.items():
                st.subheader(f"–§–∞–π–ª: {file_name}")

                data_for_table = []
                for sheet_result in sheets:
                    if 'error' in sheet_result:
                        if not show_only_good:
                            data_for_table.append({
                                '–õ–∏—Å—Ç': sheet_result['sheet'],
                                '–ü–∞–¥–µ–Ω–∏–π –¥–µ—Ñ–æ—Ä–º–∞—Ü–∏–∏': '–û—à–∏–±–∫–∞',
                                '–§–∏–Ω–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ': '–û—à–∏–±–∫–∞',
                                '–ù–∞–ª–∏—á–∏–µ –ø–∏–∫–∞': '–û—à–∏–±–∫–∞',
                                '–°—Ç–∞—Ç—É—Å': sheet_result['error']
                            })
                    else:
                        status = "‚úÖ –•–æ—Ä–æ—à–∏–π" if sheet_result['is_good_sample'] else "‚ùå –ü–ª–æ—Ö–æ–π"
                        if not show_only_good or sheet_result['is_good_sample']:
                            data_for_table.append({
                                '–õ–∏—Å—Ç': sheet_result['sheet'],
                                '–ü–∞–¥–µ–Ω–∏–π –¥–µ—Ñ–æ—Ä–º–∞—Ü–∏–∏': str(sheet_result['n_drops']),
                                '–§–∏–Ω–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ': str(sheet_result['final_drop']),
                                '–ù–∞–ª–∏—á–∏–µ –ø–∏–∫–∞': str(sheet_result['has_peak']),
                                '–°—Ç–∞—Ç—É—Å': status
                            })

                if data_for_table:
                    df_results = pd.DataFrame(data_for_table).astype(str)
                    st.dataframe(df_results)
                else:
                    st.info("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        else:
            st.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä.")